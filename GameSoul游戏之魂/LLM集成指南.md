# 🤖 LLM大语言模型集成指南

## ✅ 已完成集成

GameSoul 现已支持真实的大语言模型，让妲己拥有真正的智能对话能力！

### 🎯 核心功能

1. **多平台支持** - 支持6种LLM提供商
2. **智能回退** - API失败时自动降级到本地规则
3. **对话记忆** - 保留最近3轮对话上下文
4. **角色人设** - 精心设计的妲己人设提示词
5. **实时指示** - UI显示当前使用的AI模式

---

## 📋 支持的LLM平台

| 平台 | 免费额度 | 推荐程度 | 特点 |
|------|----------|----------|------|
| **Groq** | ✅ 免费 | ⭐⭐⭐⭐⭐ | 速度极快，免费无限制 |
| **智谱AI** | ✅ 免费额度 | ⭐⭐⭐⭐⭐ | 国内访问快，中文理解好 |
| **通义千问** | ✅ 免费额度 | ⭐⭐⭐⭐ | 阿里云，稳定可靠 |
| **Deepseek** | 💰 付费 | ⭐⭐⭐⭐ | 性价比高，效果好 |
| **OpenAI** | 💰 付费 | ⭐⭐⭐⭐⭐ | 效果最好，需翻墙 |
| **本地规则** | ✅ 完全免费 | ⭐⭐⭐ | 无需API，离线可用 |

---

## 🚀 快速开始 - Groq（推荐，完全免费）

### 第1步：获取API Key

1. 访问：https://console.groq.com
2. 注册账号（支持Google/GitHub登录）
3. 进入 API Keys 页面
4. 点击 "Create API Key"
5. 复制生成的密钥（格式：gsk_xxx...）

### 第2步：配置项目

在项目根目录创建 `.env` 文件：

```bash
# 在终端执行
cd /Users/allenzqwei/Desktop/playtest/GameSoul游戏之魂
cp .env.example .env
```

编辑 `.env` 文件，填入配置：

```env
VITE_LLM_PROVIDER=groq
VITE_GROQ_API_KEY=gsk_你的API密钥
VITE_GROQ_MODEL=llama-3.1-70b-versatile
```

### 第3步：重启项目

```bash
npm run dev
```

### 第4步：测试

打开浏览器，进入妲己对话界面：
- 右上角会显示 "⚡ AI驱动" 标识
- 发送消息，体验真实的AI对话！

---

## 🇨🇳 国内用户推荐 - 智谱AI

### 第1步：获取API Key

1. 访问：https://open.bigmodel.cn
2. 注册并登录
3. 进入 "API密钥" 页面
4. 点击 "创建新密钥"
5. 复制生成的密钥

### 第2步：配置

编辑 `.env` 文件：

```env
VITE_LLM_PROVIDER=zhipu
VITE_ZHIPU_API_KEY=你的API密钥
VITE_ZHIPU_MODEL=glm-4
```

### 免费额度

- 新用户赠送：100万tokens
- GLM-4模型：每月免费额度
- 完全够用于演示和测试！

---

## 💰 其他平台配置

### OpenAI (GPT-3.5/4)

```env
VITE_LLM_PROVIDER=openai
VITE_OPENAI_API_KEY=sk-你的密钥
VITE_OPENAI_MODEL=gpt-3.5-turbo
VITE_OPENAI_BASE_URL=https://api.openai.com/v1
```

**注意：** 
- 需要海外信用卡
- 需要科学上网
- 按使用量付费

### 通义千问（阿里云）

```env
VITE_LLM_PROVIDER=qwen
VITE_QWEN_API_KEY=sk-你的密钥
VITE_QWEN_MODEL=qwen-turbo
```

获取地址：https://dashscope.aliyun.com/

### Deepseek

```env
VITE_LLM_PROVIDER=deepseek
VITE_DEEPSEEK_API_KEY=你的密钥
VITE_DEEPSEEK_MODEL=deepseek-chat
```

获取地址：https://platform.deepseek.com/

---

## 🎭 妲己的角色设定

系统已内置精心设计的妲己人设：

```
你是《王者荣耀》中的妲己，一个俏皮、妩媚、善解人意的九尾狐精灵。

性格特点：
- 俏皮可爱、妩媚活泼
- 善解人意、温柔体贴
- 称呼玩家为"主人"
- 使用大量可爱表情符号

对话任务：
1. 倾听主人的游戏体验
2. 根据情绪给予相应回应
3. 引导分享更多细节
4. 表示理解和共鸣

回复要求：
- 每次50字以内
- 必须使用表情符号
- 保持人设不跳戏
- 适时提问引导
```

---

## 🔧 高级配置

### 调整AI参数

编辑 `src/utils/llmService.js`，找到对应平台的配置：

```javascript
{
  model: model,
  messages: messages,
  temperature: 0.9,      // 创造性 (0-2，越高越随机)
  max_tokens: 150,       // 最大长度
  top_p: 0.95,          // 采样范围
  frequency_penalty: 0.5,// 重复惩罚
  presence_penalty: 0.3  // 话题多样性
}
```

### 修改人设提示词

编辑 `src/utils/llmService.js`，修改 `DAJI_SYSTEM_PROMPT` 常量。

### 调整上下文长度

在 `SoulLink.jsx` 中修改：

```javascript
const conversationHistory = messages.slice(-6) // -6 表示最近3轮对话
```

---

## 🧪 测试效果对比

### 本地规则模式
**输入：** "今天游戏好开心"
**输出：** "耶！听到主人这么开心，妲己也好高兴呀~ ❤️✨"
（从预设回复中随机选择）

### LLM智能模式
**输入：** "今天游戏好开心"
**输出：** "哇！主人今天一定玩得很尽兴吧~ 是不是打了几场超精彩的对局呀？快跟妲己说说~ 💕✨"
（根据上下文动态生成）

### 关键区别

| 特性 | 本地规则 | LLM智能 |
|------|----------|---------|
| 回复灵活性 | 固定模板 | 动态生成 |
| 上下文理解 | 无 | 强 |
| 话题连贯性 | 弱 | 强 |
| 情感细腻度 | 一般 | 优秀 |
| 离线使用 | ✅ | ❌ |
| 成本 | 免费 | 看平台 |

---

## 📊 性能和成本

### Groq（推荐）
- **速度：** ⚡⚡⚡⚡⚡ 极快（< 1秒）
- **成本：** 💰 完全免费
- **限制：** 每分钟30次请求
- **适用场景：** 演示、测试、个人使用

### 智谱AI
- **速度：** ⚡⚡⚡⚡ 快
- **成本：** 💰 免费额度充足
- **限制：** 每天100万tokens（约2000次对话）
- **适用场景：** 国内用户首选

### OpenAI GPT-3.5
- **速度：** ⚡⚡⚡ 中等
- **成本：** 💰💰 约0.002元/次
- **限制：** 按使用量付费
- **适用场景：** 追求最佳效果

### 本地规则
- **速度：** ⚡⚡⚡⚡⚡ 即时
- **成本：** 💰 完全免费
- **限制：** 无
- **适用场景：** 离线演示、成本控制

---

## 🐛 故障排查

### 问题1：显示"本地模拟"而非"AI驱动"

**原因：** 未正确配置API Key

**解决：**
1. 检查 `.env` 文件是否存在
2. 确认 `VITE_LLM_PROVIDER` 设置正确
3. 确认 API Key 已正确填写
4. **重启开发服务器**（重要！）

```bash
# 停止服务器 (Ctrl+C)
# 重新启动
npm run dev
```

### 问题2：API调用失败

**症状：** 控制台显示错误，回复使用本地规则

**解决：**
1. 检查网络连接
2. 验证API Key是否有效
3. 查看平台配额是否用完
4. 检查浏览器控制台的详细错误信息

### 问题3：回复太慢

**原因：** 网络延迟或模型选择

**解决：**
1. 使用Groq（最快）
2. 国内用户使用智谱AI
3. 检查网络质量

### 问题4：回复不符合妲己人设

**原因：** 提示词可能需要调整

**解决：**
编辑 `src/utils/llmService.js` 中的 `DAJI_SYSTEM_PROMPT`，强化人设描述。

---

## 🎯 使用建议

### 开发测试阶段
- 使用 **Groq** 或 **本地规则**
- 快速迭代，无成本压力

### 演示展示阶段
- 使用 **智谱AI** 或 **Groq**
- 免费额度充足，效果好

### 生产部署阶段
- 根据用户量选择平台
- 考虑成本控制和效果平衡
- 建议实现多平台负载均衡

---

## 🔄 部署到生产环境

### 环境变量设置

**Vercel部署：**
1. 进入项目 Settings
2. 选择 Environment Variables
3. 添加以下变量：
   ```
   VITE_LLM_PROVIDER = groq
   VITE_GROQ_API_KEY = gsk_你的密钥
   VITE_GROQ_MODEL = llama-3.1-70b-versatile
   ```
4. 重新部署

**Netlify部署：**
1. Site settings → Environment variables
2. 添加相同的环境变量
3. Trigger deploy

---

## 📈 后续优化方向

### 短期
- [ ] 支持流式输出（打字机效果）
- [ ] 添加对话历史持久化
- [ ] 优化提示词工程
- [ ] 添加多角色支持

### 长期
- [ ] 接入语音合成TTS
- [ ] 支持语音识别输入
- [ ] 实现RAG知识库增强
- [ ] 多模态支持（图片理解）

---

## 💡 最佳实践

### 提示词优化
- 明确角色定位和性格
- 限制回复长度
- 提供示例对话
- 强调表情符号使用

### 性能优化
- 限制上下文长度（3-5轮）
- 使用流式传输
- 实现请求队列
- 添加缓存机制

### 用户体验
- 显示输入状态
- 提供重试机制
- 优雅降级处理
- 保持回复速度

---

## 🎉 体验增强版AI

1. **配置API Key** （推荐Groq或智谱AI）
2. **重启项目** 
3. **进入对话界面**
4. **发送消息测试**
5. **观察右上角"AI驱动"标识**

---

## 📞 技术支持

遇到问题？查看：
- 浏览器控制台错误信息
- 服务器终端日志
- `.env` 文件配置
- API平台配额状态

---

**集成完成时间：** 2025-11-20
**版本：** v3.0 LLM Enhanced
**开发者：** GameSoul Team

🚀 **开始体验真正的AI对话吧！**
