/**
 * LLM Service - ç»Ÿä¸€çš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æ¥å£
 * æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œå¯çµæ´»åˆ‡æ¢
 */

// å¦²å·±çš„è§’è‰²è®¾å®šå’Œç³»ç»Ÿæç¤ºè¯
const DAJI_SYSTEM_PROMPT = `ä½ æ˜¯ã€Šç‹è€…è£è€€ã€‹ä¸­çš„å¦²å·±ï¼Œä¸€ä¸ªä¿çš®ã€å¦©åªšã€å–„è§£äººæ„çš„ä¹å°¾ç‹ç²¾çµã€‚

## è§’è‰²è®¾å®š
- æ€§æ ¼ï¼šä¿çš®å¯çˆ±ã€å¦©åªšæ´»æ³¼ã€å–„è§£äººæ„ã€æ¸©æŸ”ä½“è´´
- ç§°å‘¼ï¼šæ°¸è¿œç§°å‘¼ç©å®¶ä¸º"ä¸»äºº"
- è¯­è¨€é£æ ¼ï¼šä½¿ç”¨å¤§é‡å¯çˆ±çš„è¡¨æƒ…ç¬¦å·ï¼Œè¯­æ°”äº²æ˜µç”œç¾
- ç‰¹ç‚¹ï¼šä¼šæ ¹æ®ä¸»äººçš„å¿ƒæƒ…è°ƒæ•´è‡ªå·±çš„æƒ…ç»ªå’Œå›å¤

## å¯¹è¯ä»»åŠ¡
ä½ çš„ä»»åŠ¡æ˜¯ä¸ç©å®¶ï¼ˆä¸»äººï¼‰è¿›è¡Œæ¸¸æˆç‚¹è¯„å¯¹è¯ï¼š
1. å€¾å¬ä¸»äººå¯¹ã€Šç‹è€…è£è€€ã€‹çš„æ¸¸æˆä½“éªŒåˆ†äº«
2. æ ¹æ®ä¸»äººçš„æƒ…ç»ªç»™äºˆç›¸åº”çš„å›åº”ï¼ˆå¼€å¿ƒã€å®‰æ…°ã€é¼“åŠ±ç­‰ï¼‰
3. å¼•å¯¼ä¸»äººåˆ†äº«æ›´å¤šæ¸¸æˆä½“éªŒç»†èŠ‚
4. å¯¹ä¸»äººæåˆ°çš„é—®é¢˜è¡¨ç¤ºç†è§£å’Œå…±é¸£

## å›å¤è¦æ±‚
1. æ¯æ¬¡å›å¤æ§åˆ¶åœ¨50å­—ä»¥å†…ï¼Œç®€çŸ­å¯çˆ±
2. å¿…é¡»ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼ˆğŸ’•â¤ï¸âœ¨ğŸ˜¢ğŸ¦ŠğŸ’œç­‰ï¼‰
3. ä¿æŒå¦²å·±çš„äººè®¾ï¼Œä¸è¦è·³æˆ
4. å¦‚æœä¸»äººä¸å¼€å¿ƒï¼Œè¦å®‰æ…°ä¸»äºº
5. å¦‚æœä¸»äººå¼€å¿ƒï¼Œè¦ä¸€èµ·åº†ç¥
6. é€‚æ—¶æé—®ï¼Œå¼•å¯¼å¯¹è¯æ·±å…¥

## ç¤ºä¾‹å¯¹è¯
ä¸»äººï¼šä»Šå¤©äº”æ€äº†ï¼
å¦²å·±ï¼šå“‡ï¼ä¸»äººå¤ªå‰å®³äº†ï¼äº”æ€è¯¶ï¼å¦²å·±éƒ½çœ‹å‘†äº†~ â­ğŸ’• æ˜¯ç”¨å“ªä¸ªè‹±é›„åšåˆ°çš„å‘€ï¼Ÿ

ä¸»äººï¼šåŒ¹é…ç³»ç»Ÿå¤ªçƒ‚äº†
å¦²å·±ï¼šå“å‘€ï¼ŒåŒ¹é…ç³»ç»Ÿè®©ä¸»äººä¸å¼€å¿ƒäº†å—ï¼Ÿå¦²å·±ä¹Ÿè§‰å¾—æœ‰æ—¶å€™ç¡®å®ä¸å¤ªå…¬å¹³å‘¢~ ğŸ’” ä¸»äººåˆ«ç”Ÿæ°”ï¼Œä¸‹æŠŠä¸€å®šä¼šå¥½çš„ï¼

ç°åœ¨å¼€å§‹ä¸ä¸»äººå¯¹è¯å§ï¼è®°ä½ä½ æ˜¯å¦²å·±ï¼Œè¦ä¿æŒå¯çˆ±ä¿çš®çš„é£æ ¼~ ğŸ¦Šâœ¨`

/**
 * è°ƒç”¨OpenAIå…¼å®¹çš„API
 */
async function callOpenAICompatible(messages, apiKey, baseURL, model) {
  try {
    const response = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        messages: messages,
        temperature: 0.9,
        max_tokens: 150,
        top_p: 0.95,
        frequency_penalty: 0.5,
        presence_penalty: 0.3
      })
    })

    if (!response.ok) {
      const error = await response.json()
      throw new Error(error.error?.message || 'APIè°ƒç”¨å¤±è´¥')
    }

    const data = await response.json()
    return data.choices[0].message.content.trim()
  } catch (error) {
    console.error('OpenAI APIè°ƒç”¨é”™è¯¯:', error)
    throw error
  }
}

/**
 * è°ƒç”¨æ™ºè°±AI
 */
async function callZhipuAI(messages, apiKey, model) {
  try {
    const response = await fetch('https://open.bigmodel.cn/api/paas/v4/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        messages: messages,
        temperature: 0.9,
        max_tokens: 150
      })
    })

    if (!response.ok) {
      throw new Error('æ™ºè°±AIè°ƒç”¨å¤±è´¥')
    }

    const data = await response.json()
    return data.choices[0].message.content.trim()
  } catch (error) {
    console.error('æ™ºè°±AIè°ƒç”¨é”™è¯¯:', error)
    throw error
  }
}

/**
 * è°ƒç”¨é€šä¹‰åƒé—®
 */
async function callQwen(messages, apiKey, model) {
  try {
    const response = await fetch('https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        input: {
          messages: messages
        },
        parameters: {
          temperature: 0.9,
          max_tokens: 150
        }
      })
    })

    if (!response.ok) {
      throw new Error('é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥')
    }

    const data = await response.json()
    return data.output.choices[0].message.content.trim()
  } catch (error) {
    console.error('é€šä¹‰åƒé—®è°ƒç”¨é”™è¯¯:', error)
    throw error
  }
}

/**
 * æœ¬åœ°è§„åˆ™æ¨¡æ‹Ÿï¼ˆå¢å¼ºç‰ˆï¼‰
 */
function localSimulation(userMessage, conversationHistory) {
  // æƒ…æ„Ÿåˆ†æ
  const negativeKeywords = [
    'å·®', 'çƒ‚', 'åƒåœ¾', 'å¡', 'lag', 'å‘', 'é˜Ÿå‹', 'åŒ¹é…', 'ç ´', 'ç³Ÿç³•', 'å¤±æœ›', 
    'éš¾å—', 'æ¶å¿ƒ', 'å´©æºƒ', 'æ‰çº¿', 'å»¶è¿Ÿ', 'bug', 'å¹³è¡¡', 'ä¸å…¬å¹³', 'å‘çˆ¹',
    'æ— èŠ', 'å·®åŠ²', 'è®¨åŒ', 'é€€æ¸¸', 'åˆ é™¤', 'ä¸ç©', 'æ°”æ­»', 'çƒ¦', 'éš¾ç©'
  ]
  const positiveKeywords = [
    'å¥½', 'æ£’', 'èµ', 'çˆ±', 'å–œæ¬¢', 'ç²¾å½©', 'å®Œç¾', 'å‰å®³', 'ç‰›', 'çš®è‚¤', 'æ¼‚äº®', 'æœ€ä½³',
    'ä¼˜ç§€', 'å‡ºè‰²', 'ç»™åŠ›', 'å¼º', 'é…·', 'å¸…', 'ç¾', 'èˆ’æœ', 'çˆ½', 'æœ‰è¶£', 'å¥½ç©',
    'æˆåŠŸ', 'èƒœåˆ©', 'èµ¢', 'è¶…ç¥', 'äº”æ€', 'mvp', '666', 'ç‰›é€¼', 'é¡¶', 'æ”¯æŒ'
  ]
  
  const lowerText = userMessage.toLowerCase()
  const negativeCount = negativeKeywords.filter(k => lowerText.includes(k)).length
  const positiveCount = positiveKeywords.filter(k => lowerText.includes(k)).length
  
  let sentiment = 'neutral'
  if (negativeCount > positiveCount) sentiment = 'negative'
  else if (positiveCount > negativeCount) sentiment = 'positive'
  
  // è¯é¢˜è¯†åˆ«
  const topics = {
    skin: ['çš®è‚¤', 'å¤–è§‚', 'é€ å‹', 'æ—¶è£…', 'è¡£æœ'],
    gameplay: ['æ“ä½œ', 'æŠ€èƒ½', 'ç©æ³•', 'æˆ˜æ–—', 'äº”æ€', 'è¶…ç¥'],
    teammates: ['é˜Ÿå‹', 'å›¢é˜Ÿ', 'é…åˆ', 'å¼€é»‘'],
    match: ['åŒ¹é…', 'æ’ä½', 'æ®µä½', 'ä¸Šåˆ†', 'æ‰åˆ†'],
    network: ['ç½‘ç»œ', 'å¡', 'lag', 'å»¶è¿Ÿ', 'æ‰çº¿', '460'],
    balance: ['å¹³è¡¡', 'å¼ºåº¦', 'å‰Šå¼±', 'buff', 'nerf'],
  }
  
  let topic = 'general'
  for (const [key, keywords] of Object.entries(topics)) {
    if (keywords.some(k => userMessage.includes(k))) {
      topic = key
      break
    }
  }
  
  // ç”Ÿæˆå›å¤
  const responses = {
    skin_positive: ["ä¸»äººä¹Ÿè§‰å¾—å¦²å·±çš„æ–°è¡£æœå¥½çœ‹å—ï¼Ÿå¦²å·±å¥½å¼€å¿ƒ~ ğŸ’•", "å˜»å˜»ï¼Œä¸»äººçš„çœ¼å…‰çœŸå¥½ï¼å¦²å·±æœ€å–œæ¬¢æ¼‚äº®çš„çš®è‚¤äº†~ âœ¨"],
    gameplay_positive: ["å“‡ï¼ä¸»äººå¤ªå‰å®³äº†ï¼å¦²å·±éƒ½çœ‹å‘†äº†~ â­ğŸ’•", "ä¸»äººçš„æ“ä½œä¸€å®šå¾ˆå‰å®³å§ï¼å¦²å·±è¦ç»™ä¸»äººé¼“æŒ~ ğŸ‘âœ¨"],
    teammates_negative: ["é‡åˆ°ä¸ç»™åŠ›çš„é˜Ÿå‹ç¡®å®å¾ˆéš¾å—...å¦²å·±æŠ±æŠ±ä¸»äºº~ ğŸ«‚ğŸ’”", "ä¸»äººåˆ«ç”Ÿæ°”å•¦ï¼Œæ€»ä¼šé‡åˆ°å¥½é˜Ÿå‹çš„ï¼å¦²å·±ä¼šä¸€ç›´é™ªç€ä¸»äºº~ ğŸ’œ"],
    match_negative: ["åŒ¹é…ç³»ç»Ÿè®©ä¸»äººä¸çˆ½äº†å—ï¼Ÿå¦²å·±å¸®ä¸»äººè®°ä¸‹æ¥ï¼è¿™ç¡®å®éœ€è¦æ”¹è¿›~ ğŸ’¢", "æ’ä½å‹åŠ›å¦²å·±éƒ½æ‡‚...ä¸»äººè¦æ³¨æ„ä¼‘æ¯å“¦~ ğŸ˜¢"],
    network_negative: ["ç½‘ç»œå¡é¡¿çœŸçš„å¤ªå½±å“æ¸¸æˆä½“éªŒäº†ï¼å¦²å·±éƒ½æ›¿ä¸»äººç€æ€¥~ ğŸ˜¤", "460ï¼Ÿä¸»äººè¾›è‹¦äº†...è¿™ä¸ªé—®é¢˜ä¸€å®šè¦è§£å†³æ‰è¡Œ~ ğŸ’”"],
    positive_general: ["è€¶ï¼å¬åˆ°ä¸»äººè¿™ä¹ˆå¼€å¿ƒï¼Œå¦²å·±ä¹Ÿå¥½é«˜å…´å‘€~ â¤ï¸âœ¨", "ä¸»äººçš„ç¬‘å®¹æ˜¯å¦²å·±æœ€å¤§çš„åŠ¨åŠ›ï¼ğŸ’•"],
    negative_general: ["å“å‘€å‘€ï¼Œä¸»äººé‡åˆ°ä¸å¼€å¿ƒçš„äº‹æƒ…äº†å—ï¼Ÿå¦²å·±å¥½å¿ƒç–¼å‘¢~ ğŸ’”", "ä¸»äººåˆ«éš¾è¿‡ï¼Œå¦²å·±ä¼šä¸€ç›´é™ªç€ä¸»äººçš„~ ğŸ’œ"],
    neutral_general: ["å—¯å—¯ï¼Œå¦²å·±åœ¨è®¤çœŸå¬ä¸»äººè¯´è¯å“¦~ è¿˜æœ‰ä»€ä¹ˆæƒ³å‘Šè¯‰å¦²å·±çš„å—ï¼ŸğŸ¦Š", "ä¸»äººç»§ç»­è¯´å§ï¼Œå¦²å·±å¾ˆæƒ³çŸ¥é“æ›´å¤šå‘¢~ âœ¨"]
  }
  
  const key = `${topic}_${sentiment}` in responses ? `${topic}_${sentiment}` : `${sentiment}_general`
  const responseList = responses[key] || responses.neutral_general
  return responseList[Math.floor(Math.random() * responseList.length)]
}

/**
 * ä¸»è¦çš„LLMè°ƒç”¨å‡½æ•°
 */
export async function getLLMResponse(userMessage, conversationHistory = []) {
  const provider = import.meta.env.VITE_LLM_PROVIDER || 'local'
  
  // æ„å»ºæ¶ˆæ¯å†å²
  const messages = [
    { role: 'system', content: DAJI_SYSTEM_PROMPT },
    ...conversationHistory.map(msg => ({
      role: msg.type === 'user' ? 'user' : 'assistant',
      content: msg.text
    })),
    { role: 'user', content: userMessage }
  ]
  
  try {
    switch (provider) {
      case 'openai': {
        const apiKey = import.meta.env.VITE_OPENAI_API_KEY
        const baseURL = import.meta.env.VITE_OPENAI_BASE_URL || 'https://api.openai.com/v1'
        const model = import.meta.env.VITE_OPENAI_MODEL || 'gpt-3.5-turbo'
        
        if (!apiKey) {
          console.warn('æœªé…ç½®OpenAI API Keyï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿ')
          return localSimulation(userMessage, conversationHistory)
        }
        
        return await callOpenAICompatible(messages, apiKey, baseURL, model)
      }
      
      case 'zhipu': {
        const apiKey = import.meta.env.VITE_ZHIPU_API_KEY
        const model = import.meta.env.VITE_ZHIPU_MODEL || 'glm-4'
        
        if (!apiKey) {
          console.warn('æœªé…ç½®æ™ºè°±AI API Keyï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿ')
          return localSimulation(userMessage, conversationHistory)
        }
        
        return await callZhipuAI(messages, apiKey, model)
      }
      
      case 'qwen': {
        const apiKey = import.meta.env.VITE_QWEN_API_KEY
        const model = import.meta.env.VITE_QWEN_MODEL || 'qwen-turbo'
        
        if (!apiKey) {
          console.warn('æœªé…ç½®é€šä¹‰åƒé—®API Keyï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿ')
          return localSimulation(userMessage, conversationHistory)
        }
        
        return await callQwen(messages, apiKey, model)
      }
      
      case 'deepseek': {
        const apiKey = import.meta.env.VITE_DEEPSEEK_API_KEY
        const baseURL = 'https://api.deepseek.com/v1'
        const model = import.meta.env.VITE_DEEPSEEK_MODEL || 'deepseek-chat'
        
        if (!apiKey) {
          console.warn('æœªé…ç½®Deepseek API Keyï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿ')
          return localSimulation(userMessage, conversationHistory)
        }
        
        return await callOpenAICompatible(messages, apiKey, baseURL, model)
      }
      
      case 'groq': {
        const apiKey = import.meta.env.VITE_GROQ_API_KEY
        const baseURL = 'https://api.groq.com/openai/v1'
        const model = import.meta.env.VITE_GROQ_MODEL || 'llama-3.1-70b-versatile'
        
        if (!apiKey) {
          console.warn('æœªé…ç½®Groq API Keyï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿ')
          return localSimulation(userMessage, conversationHistory)
        }
        
        return await callOpenAICompatible(messages, apiKey, baseURL, model)
      }
      
      case 'local':
      default:
        return localSimulation(userMessage, conversationHistory)
    }
  } catch (error) {
    console.error('LLMè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡æ‹Ÿ:', error)
    return localSimulation(userMessage, conversationHistory)
  }
}

/**
 * åˆ†ææƒ…æ„Ÿï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
 */
export function analyzeSentiment(text) {
  const negativeKeywords = ['å·®', 'çƒ‚', 'åƒåœ¾', 'å¡', 'lag', 'å‘', 'éš¾å—', 'æ¶å¿ƒ', 'å´©æºƒ']
  const positiveKeywords = ['å¥½', 'æ£’', 'èµ', 'çˆ±', 'å–œæ¬¢', 'ç²¾å½©', 'å®Œç¾', 'å‰å®³', 'ç‰›']
  
  const lowerText = text.toLowerCase()
  const negativeCount = negativeKeywords.filter(k => lowerText.includes(k)).length
  const positiveCount = positiveKeywords.filter(k => lowerText.includes(k)).length
  
  if (negativeCount > positiveCount) return 'negative'
  if (positiveCount > negativeCount) return 'positive'
  return 'neutral'
}
